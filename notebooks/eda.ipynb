{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1339c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d69c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load each raw CSV into a pandas DataFrame\n",
    "click = pd.read_csv(\"/Users/shwe/Desktop/assignment_1_mle/data/feature_clickstream.csv\")\n",
    "attrs = pd.read_csv(\"/Users/shwe/Desktop/assignment_1_mle/data/features_attributes.csv\")\n",
    "fin   = pd.read_csv(\"/Users/shwe/Desktop/assignment_1_mle/data/features_financials.csv\")\n",
    "loan  = pd.read_csv(\"/Users/shwe/Desktop/assignment_1_mle/data/lms_loan_daily.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f88768a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fe_1</th>\n",
       "      <th>fe_2</th>\n",
       "      <th>fe_3</th>\n",
       "      <th>fe_4</th>\n",
       "      <th>fe_5</th>\n",
       "      <th>fe_6</th>\n",
       "      <th>fe_7</th>\n",
       "      <th>fe_8</th>\n",
       "      <th>fe_9</th>\n",
       "      <th>fe_10</th>\n",
       "      <th>...</th>\n",
       "      <th>fe_13</th>\n",
       "      <th>fe_14</th>\n",
       "      <th>fe_15</th>\n",
       "      <th>fe_16</th>\n",
       "      <th>fe_17</th>\n",
       "      <th>fe_18</th>\n",
       "      <th>fe_19</th>\n",
       "      <th>fe_20</th>\n",
       "      <th>Customer_ID</th>\n",
       "      <th>snapshot_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>118</td>\n",
       "      <td>80</td>\n",
       "      <td>121</td>\n",
       "      <td>55</td>\n",
       "      <td>193</td>\n",
       "      <td>111</td>\n",
       "      <td>112</td>\n",
       "      <td>-101</td>\n",
       "      <td>83</td>\n",
       "      <td>...</td>\n",
       "      <td>-16</td>\n",
       "      <td>-81</td>\n",
       "      <td>-126</td>\n",
       "      <td>114</td>\n",
       "      <td>35</td>\n",
       "      <td>85</td>\n",
       "      <td>-73</td>\n",
       "      <td>76</td>\n",
       "      <td>CUS_0x1037</td>\n",
       "      <td>2023-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-108</td>\n",
       "      <td>182</td>\n",
       "      <td>123</td>\n",
       "      <td>4</td>\n",
       "      <td>-56</td>\n",
       "      <td>27</td>\n",
       "      <td>25</td>\n",
       "      <td>-6</td>\n",
       "      <td>284</td>\n",
       "      <td>222</td>\n",
       "      <td>...</td>\n",
       "      <td>-14</td>\n",
       "      <td>-96</td>\n",
       "      <td>200</td>\n",
       "      <td>35</td>\n",
       "      <td>130</td>\n",
       "      <td>94</td>\n",
       "      <td>111</td>\n",
       "      <td>75</td>\n",
       "      <td>CUS_0x1069</td>\n",
       "      <td>2023-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-13</td>\n",
       "      <td>8</td>\n",
       "      <td>87</td>\n",
       "      <td>166</td>\n",
       "      <td>214</td>\n",
       "      <td>-98</td>\n",
       "      <td>215</td>\n",
       "      <td>152</td>\n",
       "      <td>129</td>\n",
       "      <td>139</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>86</td>\n",
       "      <td>171</td>\n",
       "      <td>125</td>\n",
       "      <td>-130</td>\n",
       "      <td>354</td>\n",
       "      <td>17</td>\n",
       "      <td>302</td>\n",
       "      <td>CUS_0x114a</td>\n",
       "      <td>2023-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-85</td>\n",
       "      <td>45</td>\n",
       "      <td>200</td>\n",
       "      <td>89</td>\n",
       "      <td>128</td>\n",
       "      <td>54</td>\n",
       "      <td>76</td>\n",
       "      <td>51</td>\n",
       "      <td>61</td>\n",
       "      <td>139</td>\n",
       "      <td>...</td>\n",
       "      <td>172</td>\n",
       "      <td>96</td>\n",
       "      <td>174</td>\n",
       "      <td>163</td>\n",
       "      <td>37</td>\n",
       "      <td>207</td>\n",
       "      <td>180</td>\n",
       "      <td>118</td>\n",
       "      <td>CUS_0x1184</td>\n",
       "      <td>2023-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55</td>\n",
       "      <td>120</td>\n",
       "      <td>226</td>\n",
       "      <td>-86</td>\n",
       "      <td>253</td>\n",
       "      <td>97</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "      <td>103</td>\n",
       "      <td>126</td>\n",
       "      <td>...</td>\n",
       "      <td>76</td>\n",
       "      <td>43</td>\n",
       "      <td>183</td>\n",
       "      <td>159</td>\n",
       "      <td>-26</td>\n",
       "      <td>104</td>\n",
       "      <td>118</td>\n",
       "      <td>184</td>\n",
       "      <td>CUS_0x1297</td>\n",
       "      <td>2023-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   fe_1  fe_2  fe_3  fe_4  fe_5  fe_6  fe_7  fe_8  fe_9  fe_10  ...  fe_13  \\\n",
       "0    63   118    80   121    55   193   111   112  -101     83  ...    -16   \n",
       "1  -108   182   123     4   -56    27    25    -6   284    222  ...    -14   \n",
       "2   -13     8    87   166   214   -98   215   152   129    139  ...     26   \n",
       "3   -85    45   200    89   128    54    76    51    61    139  ...    172   \n",
       "4    55   120   226   -86   253    97   107    68   103    126  ...     76   \n",
       "\n",
       "   fe_14  fe_15  fe_16  fe_17  fe_18  fe_19  fe_20  Customer_ID  snapshot_date  \n",
       "0    -81   -126    114     35     85    -73     76   CUS_0x1037     2023-01-01  \n",
       "1    -96    200     35    130     94    111     75   CUS_0x1069     2023-01-01  \n",
       "2     86    171    125   -130    354     17    302   CUS_0x114a     2023-01-01  \n",
       "3     96    174    163     37    207    180    118   CUS_0x1184     2023-01-01  \n",
       "4     43    183    159    -26    104    118    184   CUS_0x1297     2023-01-01  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "click.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b676d5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12500 entries, 0 to 12499\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Customer_ID    12500 non-null  object\n",
      " 1   Name           12500 non-null  object\n",
      " 2   Age            12500 non-null  object\n",
      " 3   SSN            12500 non-null  object\n",
      " 4   Occupation     12500 non-null  object\n",
      " 5   snapshot_date  12500 non-null  object\n",
      "dtypes: object(6)\n",
      "memory usage: 586.1+ KB\n"
     ]
    }
   ],
   "source": [
    "attrs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e536849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer_ID</th>\n",
       "      <th>Annual_Income</th>\n",
       "      <th>Monthly_Inhand_Salary</th>\n",
       "      <th>Num_Bank_Accounts</th>\n",
       "      <th>Num_Credit_Card</th>\n",
       "      <th>Interest_Rate</th>\n",
       "      <th>Num_of_Loan</th>\n",
       "      <th>Type_of_Loan</th>\n",
       "      <th>Delay_from_due_date</th>\n",
       "      <th>Num_of_Delayed_Payment</th>\n",
       "      <th>...</th>\n",
       "      <th>Credit_Mix</th>\n",
       "      <th>Outstanding_Debt</th>\n",
       "      <th>Credit_Utilization_Ratio</th>\n",
       "      <th>Credit_History_Age</th>\n",
       "      <th>Payment_of_Min_Amount</th>\n",
       "      <th>Total_EMI_per_month</th>\n",
       "      <th>Amount_invested_monthly</th>\n",
       "      <th>Payment_Behaviour</th>\n",
       "      <th>Monthly_Balance</th>\n",
       "      <th>snapshot_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CUS_0x1000</td>\n",
       "      <td>30625.94</td>\n",
       "      <td>2706.161667</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>Credit-Builder Loan, and Home Equity Loan</td>\n",
       "      <td>57</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>Bad</td>\n",
       "      <td>1562.91</td>\n",
       "      <td>30.077191</td>\n",
       "      <td>10 Years and 9 Months</td>\n",
       "      <td>Yes</td>\n",
       "      <td>42.941090</td>\n",
       "      <td>77.31427572208112</td>\n",
       "      <td>High_spent_Medium_value_payments</td>\n",
       "      <td>400.36080052211616</td>\n",
       "      <td>2023-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CUS_0x1009</td>\n",
       "      <td>52312.68_</td>\n",
       "      <td>4250.390000</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>Not Specified, Home Equity Loan, Credit-Builde...</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>_</td>\n",
       "      <td>202.68</td>\n",
       "      <td>40.286997</td>\n",
       "      <td>31 Years and 0 Months</td>\n",
       "      <td>Yes</td>\n",
       "      <td>108.366467</td>\n",
       "      <td>58.66019164829086</td>\n",
       "      <td>High_spent_Medium_value_payments</td>\n",
       "      <td>508.01234122645366</td>\n",
       "      <td>2025-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CUS_0x100b</td>\n",
       "      <td>113781.38999999998</td>\n",
       "      <td>9549.782500</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>Good</td>\n",
       "      <td>1030.2</td>\n",
       "      <td>28.592943</td>\n",
       "      <td>15 Years and 10 Months</td>\n",
       "      <td>No</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>617.0792665202719</td>\n",
       "      <td>High_spent_Small_value_payments</td>\n",
       "      <td>597.8989834797281</td>\n",
       "      <td>2024-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CUS_0x1011</td>\n",
       "      <td>58918.47</td>\n",
       "      <td>5208.872500</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>Student Loan, Credit-Builder Loan, and Debt Co...</td>\n",
       "      <td>27</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>Standard</td>\n",
       "      <td>473.14</td>\n",
       "      <td>27.829959</td>\n",
       "      <td>15 Years and 10 Months</td>\n",
       "      <td>Yes</td>\n",
       "      <td>123.434939</td>\n",
       "      <td>383.35084463651407</td>\n",
       "      <td>Low_spent_Medium_value_payments</td>\n",
       "      <td>294.1014665671429</td>\n",
       "      <td>2023-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CUS_0x1013</td>\n",
       "      <td>98620.98</td>\n",
       "      <td>7962.415000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>Student Loan, Debt Consolidation Loan, and Per...</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>Good</td>\n",
       "      <td>1233.51</td>\n",
       "      <td>26.524864</td>\n",
       "      <td>17 Years and 10 Months</td>\n",
       "      <td>No</td>\n",
       "      <td>228.018084</td>\n",
       "      <td>332.3337079767732</td>\n",
       "      <td>High_spent_Medium_value_payments</td>\n",
       "      <td>485.8897083704929</td>\n",
       "      <td>2023-12-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Customer_ID       Annual_Income  Monthly_Inhand_Salary  Num_Bank_Accounts  \\\n",
       "0  CUS_0x1000            30625.94            2706.161667                  6   \n",
       "1  CUS_0x1009           52312.68_            4250.390000                  6   \n",
       "2  CUS_0x100b  113781.38999999998            9549.782500                  1   \n",
       "3  CUS_0x1011            58918.47            5208.872500                  3   \n",
       "4  CUS_0x1013            98620.98            7962.415000                  3   \n",
       "\n",
       "   Num_Credit_Card  Interest_Rate Num_of_Loan  \\\n",
       "0                5             27           2   \n",
       "1                5             17           4   \n",
       "2                4              1           0   \n",
       "3                3             17           3   \n",
       "4                3              6           3   \n",
       "\n",
       "                                        Type_of_Loan  Delay_from_due_date  \\\n",
       "0          Credit-Builder Loan, and Home Equity Loan                   57   \n",
       "1  Not Specified, Home Equity Loan, Credit-Builde...                    5   \n",
       "2                                                NaN                   14   \n",
       "3  Student Loan, Credit-Builder Loan, and Debt Co...                   27   \n",
       "4  Student Loan, Debt Consolidation Loan, and Per...                   12   \n",
       "\n",
       "  Num_of_Delayed_Payment  ... Credit_Mix  Outstanding_Debt  \\\n",
       "0                     26  ...        Bad           1562.91   \n",
       "1                     18  ...          _            202.68   \n",
       "2                      8  ...       Good            1030.2   \n",
       "3                     13  ...   Standard            473.14   \n",
       "4                      9  ...       Good           1233.51   \n",
       "\n",
       "  Credit_Utilization_Ratio      Credit_History_Age  Payment_of_Min_Amount  \\\n",
       "0                30.077191   10 Years and 9 Months                    Yes   \n",
       "1                40.286997   31 Years and 0 Months                    Yes   \n",
       "2                28.592943  15 Years and 10 Months                     No   \n",
       "3                27.829959  15 Years and 10 Months                    Yes   \n",
       "4                26.524864  17 Years and 10 Months                     No   \n",
       "\n",
       "  Total_EMI_per_month Amount_invested_monthly  \\\n",
       "0           42.941090       77.31427572208112   \n",
       "1          108.366467       58.66019164829086   \n",
       "2            0.000000       617.0792665202719   \n",
       "3          123.434939      383.35084463651407   \n",
       "4          228.018084       332.3337079767732   \n",
       "\n",
       "                  Payment_Behaviour     Monthly_Balance snapshot_date  \n",
       "0  High_spent_Medium_value_payments  400.36080052211616    2023-05-01  \n",
       "1  High_spent_Medium_value_payments  508.01234122645366    2025-01-01  \n",
       "2   High_spent_Small_value_payments   597.8989834797281    2024-03-01  \n",
       "3   Low_spent_Medium_value_payments   294.1014665671429    2023-11-01  \n",
       "4  High_spent_Medium_value_payments   485.8897083704929    2023-12-01  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7e7df26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_id</th>\n",
       "      <th>Customer_ID</th>\n",
       "      <th>loan_start_date</th>\n",
       "      <th>tenure</th>\n",
       "      <th>installment_num</th>\n",
       "      <th>loan_amt</th>\n",
       "      <th>due_amt</th>\n",
       "      <th>paid_amt</th>\n",
       "      <th>overdue_amt</th>\n",
       "      <th>balance</th>\n",
       "      <th>snapshot_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CUS_0x1000_2023_05_01</td>\n",
       "      <td>CUS_0x1000</td>\n",
       "      <td>2023-05-01</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>2023-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CUS_0x1000_2023_05_01</td>\n",
       "      <td>CUS_0x1000</td>\n",
       "      <td>2023-05-01</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10000</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>2023-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CUS_0x1000_2023_05_01</td>\n",
       "      <td>CUS_0x1000</td>\n",
       "      <td>2023-05-01</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>10000</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>2023-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CUS_0x1000_2023_05_01</td>\n",
       "      <td>CUS_0x1000</td>\n",
       "      <td>2023-05-01</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>10000</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>2023-08-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CUS_0x1000_2023_05_01</td>\n",
       "      <td>CUS_0x1000</td>\n",
       "      <td>2023-05-01</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>10000</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>2023-09-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 loan_id Customer_ID loan_start_date  tenure  installment_num  \\\n",
       "0  CUS_0x1000_2023_05_01  CUS_0x1000      2023-05-01      10                0   \n",
       "1  CUS_0x1000_2023_05_01  CUS_0x1000      2023-05-01      10                1   \n",
       "2  CUS_0x1000_2023_05_01  CUS_0x1000      2023-05-01      10                2   \n",
       "3  CUS_0x1000_2023_05_01  CUS_0x1000      2023-05-01      10                3   \n",
       "4  CUS_0x1000_2023_05_01  CUS_0x1000      2023-05-01      10                4   \n",
       "\n",
       "   loan_amt  due_amt  paid_amt  overdue_amt  balance snapshot_date  \n",
       "0     10000      0.0       0.0          0.0  10000.0    2023-05-01  \n",
       "1     10000   1000.0    1000.0          0.0   9000.0    2023-06-01  \n",
       "2     10000   1000.0    1000.0          0.0   8000.0    2023-07-01  \n",
       "3     10000   1000.0       0.0       1000.0   8000.0    2023-08-01  \n",
       "4     10000   1000.0    2000.0          0.0   6000.0    2023-09-01  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57775247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 215376 entries, 0 to 215375\n",
      "Data columns (total 22 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   fe_1           215376 non-null  int64 \n",
      " 1   fe_2           215376 non-null  int64 \n",
      " 2   fe_3           215376 non-null  int64 \n",
      " 3   fe_4           215376 non-null  int64 \n",
      " 4   fe_5           215376 non-null  int64 \n",
      " 5   fe_6           215376 non-null  int64 \n",
      " 6   fe_7           215376 non-null  int64 \n",
      " 7   fe_8           215376 non-null  int64 \n",
      " 8   fe_9           215376 non-null  int64 \n",
      " 9   fe_10          215376 non-null  int64 \n",
      " 10  fe_11          215376 non-null  int64 \n",
      " 11  fe_12          215376 non-null  int64 \n",
      " 12  fe_13          215376 non-null  int64 \n",
      " 13  fe_14          215376 non-null  int64 \n",
      " 14  fe_15          215376 non-null  int64 \n",
      " 15  fe_16          215376 non-null  int64 \n",
      " 16  fe_17          215376 non-null  int64 \n",
      " 17  fe_18          215376 non-null  int64 \n",
      " 18  fe_19          215376 non-null  int64 \n",
      " 19  fe_20          215376 non-null  int64 \n",
      " 20  Customer_ID    215376 non-null  object\n",
      " 21  snapshot_date  215376 non-null  object\n",
      "dtypes: int64(20), object(2)\n",
      "memory usage: 36.2+ MB\n"
     ]
    }
   ],
   "source": [
    "click.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7da7289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate rows in click: 0\n"
     ]
    }
   ],
   "source": [
    "dup_count = click.duplicated().sum()\n",
    "print(f\"Duplicate rows in click: {dup_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c900f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Customer_IDs: 8974\n",
      "Unique snapshot_dates: 24\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique Customer_IDs:\", click['Customer_ID'].nunique())\n",
    "print(\"Unique snapshot_dates:\", click['snapshot_date'].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af583b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12500 entries, 0 to 12499\n",
      "Data columns (total 22 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Customer_ID               12500 non-null  object \n",
      " 1   Annual_Income             12500 non-null  object \n",
      " 2   Monthly_Inhand_Salary     12500 non-null  float64\n",
      " 3   Num_Bank_Accounts         12500 non-null  int64  \n",
      " 4   Num_Credit_Card           12500 non-null  int64  \n",
      " 5   Interest_Rate             12500 non-null  int64  \n",
      " 6   Num_of_Loan               12500 non-null  object \n",
      " 7   Type_of_Loan              11074 non-null  object \n",
      " 8   Delay_from_due_date       12500 non-null  int64  \n",
      " 9   Num_of_Delayed_Payment    12500 non-null  object \n",
      " 10  Changed_Credit_Limit      12500 non-null  object \n",
      " 11  Num_Credit_Inquiries      12500 non-null  float64\n",
      " 12  Credit_Mix                12500 non-null  object \n",
      " 13  Outstanding_Debt          12500 non-null  object \n",
      " 14  Credit_Utilization_Ratio  12500 non-null  float64\n",
      " 15  Credit_History_Age        12500 non-null  object \n",
      " 16  Payment_of_Min_Amount     12500 non-null  object \n",
      " 17  Total_EMI_per_month       12500 non-null  float64\n",
      " 18  Amount_invested_monthly   12500 non-null  object \n",
      " 19  Payment_Behaviour         12500 non-null  object \n",
      " 20  Monthly_Balance           12500 non-null  object \n",
      " 21  snapshot_date             12500 non-null  object \n",
      "dtypes: float64(4), int64(4), object(14)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "fin.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7076c828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null counts:\n",
      " Type_of_Loan                1426\n",
      "Customer_ID                    0\n",
      "Credit_Mix                     0\n",
      "Monthly_Balance                0\n",
      "Payment_Behaviour              0\n",
      "Amount_invested_monthly        0\n",
      "Total_EMI_per_month            0\n",
      "Payment_of_Min_Amount          0\n",
      "Credit_History_Age             0\n",
      "Credit_Utilization_Ratio       0\n",
      "Outstanding_Debt               0\n",
      "Num_Credit_Inquiries           0\n",
      "Annual_Income                  0\n",
      "Changed_Credit_Limit           0\n",
      "Num_of_Delayed_Payment         0\n",
      "Delay_from_due_date            0\n",
      "Num_of_Loan                    0\n",
      "Interest_Rate                  0\n",
      "Num_Credit_Card                0\n",
      "Num_Bank_Accounts              0\n",
      "Monthly_Inhand_Salary          0\n",
      "snapshot_date                  0\n",
      "dtype: int64 \n",
      "\n",
      "Null %:\n",
      " Type_of_Loan                11.41\n",
      "Customer_ID                  0.00\n",
      "Credit_Mix                   0.00\n",
      "Monthly_Balance              0.00\n",
      "Payment_Behaviour            0.00\n",
      "Amount_invested_monthly      0.00\n",
      "Total_EMI_per_month          0.00\n",
      "Payment_of_Min_Amount        0.00\n",
      "Credit_History_Age           0.00\n",
      "Credit_Utilization_Ratio     0.00\n",
      "Outstanding_Debt             0.00\n",
      "Num_Credit_Inquiries         0.00\n",
      "Annual_Income                0.00\n",
      "Changed_Credit_Limit         0.00\n",
      "Num_of_Delayed_Payment       0.00\n",
      "Delay_from_due_date          0.00\n",
      "Num_of_Loan                  0.00\n",
      "Interest_Rate                0.00\n",
      "Num_Credit_Card              0.00\n",
      "Num_Bank_Accounts            0.00\n",
      "Monthly_Inhand_Salary        0.00\n",
      "snapshot_date                0.00\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# null counts\n",
    "null_counts = fin.isnull().sum().sort_values(ascending=False)\n",
    "# null % \n",
    "null_pct    = (fin.isnull().mean()*100).sort_values(ascending=False).round(2)\n",
    "\n",
    "print(\"Null counts:\\n\", null_counts, \"\\n\")\n",
    "print(\"Null %:\\n\", null_pct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0325fd99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Monthly_Inhand_Salary</th>\n",
       "      <td>12500.0</td>\n",
       "      <td>4188.592303</td>\n",
       "      <td>3180.147611</td>\n",
       "      <td>303.645417</td>\n",
       "      <td>1624.937917</td>\n",
       "      <td>3087.595000</td>\n",
       "      <td>5947.364167</td>\n",
       "      <td>15204.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Num_Bank_Accounts</th>\n",
       "      <td>12500.0</td>\n",
       "      <td>16.939920</td>\n",
       "      <td>114.350815</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1756.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Num_Credit_Card</th>\n",
       "      <td>12500.0</td>\n",
       "      <td>23.172720</td>\n",
       "      <td>132.005866</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1499.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Interest_Rate</th>\n",
       "      <td>12500.0</td>\n",
       "      <td>73.213360</td>\n",
       "      <td>468.682227</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>5789.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Delay_from_due_date</th>\n",
       "      <td>12500.0</td>\n",
       "      <td>21.060880</td>\n",
       "      <td>14.863091</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>67.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Num_Credit_Inquiries</th>\n",
       "      <td>12500.0</td>\n",
       "      <td>26.695280</td>\n",
       "      <td>184.193829</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2554.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Credit_Utilization_Ratio</th>\n",
       "      <td>12500.0</td>\n",
       "      <td>32.349265</td>\n",
       "      <td>5.156815</td>\n",
       "      <td>20.100770</td>\n",
       "      <td>28.066517</td>\n",
       "      <td>32.418953</td>\n",
       "      <td>36.623650</td>\n",
       "      <td>48.199824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total_EMI_per_month</th>\n",
       "      <td>12500.0</td>\n",
       "      <td>1488.394291</td>\n",
       "      <td>8561.449910</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.496968</td>\n",
       "      <td>72.887628</td>\n",
       "      <td>169.634826</td>\n",
       "      <td>81971.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            count         mean          std         min  \\\n",
       "Monthly_Inhand_Salary     12500.0  4188.592303  3180.147611  303.645417   \n",
       "Num_Bank_Accounts         12500.0    16.939920   114.350815   -1.000000   \n",
       "Num_Credit_Card           12500.0    23.172720   132.005866    0.000000   \n",
       "Interest_Rate             12500.0    73.213360   468.682227    1.000000   \n",
       "Delay_from_due_date       12500.0    21.060880    14.863091   -5.000000   \n",
       "Num_Credit_Inquiries      12500.0    26.695280   184.193829    0.000000   \n",
       "Credit_Utilization_Ratio  12500.0    32.349265     5.156815   20.100770   \n",
       "Total_EMI_per_month       12500.0  1488.394291  8561.449910    0.000000   \n",
       "\n",
       "                                  25%          50%          75%           max  \n",
       "Monthly_Inhand_Salary     1624.937917  3087.595000  5947.364167  15204.633333  \n",
       "Num_Bank_Accounts            3.000000     6.000000     7.000000   1756.000000  \n",
       "Num_Credit_Card              4.000000     5.000000     7.000000   1499.000000  \n",
       "Interest_Rate                8.000000    14.000000    20.000000   5789.000000  \n",
       "Delay_from_due_date         10.000000    18.000000    28.000000     67.000000  \n",
       "Num_Credit_Inquiries         4.000000     6.000000    10.000000   2554.000000  \n",
       "Credit_Utilization_Ratio    28.066517    32.418953    36.623650     48.199824  \n",
       "Total_EMI_per_month         31.496968    72.887628   169.634826  81971.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# describe only numeric\n",
    "print(\"Numeric summary:\")\n",
    "display(fin.describe().T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16fc20f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type_of_Loan value counts (including NaN):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type_of_Loan</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>1426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Not Specified</th>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Credit-Builder Loan</th>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Personal Loan</th>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Debt Consolidation Loan</th>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Debt Consolidation Loan, Home Equity Loan, Auto Loan, Payday Loan, Debt Consolidation Loan, Mortgage Loan, Personal Loan, and Payday Loan</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Student Loan, Debt Consolidation Loan, Auto Loan, Not Specified, and Credit-Builder Loan</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Credit-Builder Loan, Credit-Builder Loan, Personal Loan, Student Loan, Credit-Builder Loan, Not Specified, and Payday Loan</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Student Loan, Payday Loan, Credit-Builder Loan, and Student Loan</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Auto Loan, Payday Loan, Payday Loan, Mortgage Loan, Payday Loan, and Home Equity Loan</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6261 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    count\n",
       "Type_of_Loan                                             \n",
       "NaN                                                  1426\n",
       "Not Specified                                         176\n",
       "Credit-Builder Loan                                   160\n",
       "Personal Loan                                         159\n",
       "Debt Consolidation Loan                               158\n",
       "...                                                   ...\n",
       "Debt Consolidation Loan, Home Equity Loan, Auto...      1\n",
       "Student Loan, Debt Consolidation Loan, Auto Loa...      1\n",
       "Credit-Builder Loan, Credit-Builder Loan, Perso...      1\n",
       "Student Loan, Payday Loan, Credit-Builder Loan,...      1\n",
       "Auto Loan, Payday Loan, Payday Loan, Mortgage L...      1\n",
       "\n",
       "[6261 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# How many unique loan types, and how many missing?\n",
    "print(\"Type_of_Loan value counts (including NaN):\")\n",
    "display(fin['Type_of_Loan'].value_counts(dropna=False).to_frame(\"count\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "690f3204",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Customer_ID: string (nullable = true)\n",
      " |-- snapshot_date: date (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- SSN: string (nullable = true)\n",
      " |-- Occupation: string (nullable = true)\n",
      " |-- Annual_Income: double (nullable = true)\n",
      " |-- Monthly_Inhand_Salary: double (nullable = true)\n",
      " |-- Num_Bank_Accounts: integer (nullable = true)\n",
      " |-- Num_Credit_Card: integer (nullable = true)\n",
      " |-- Interest_Rate: double (nullable = true)\n",
      " |-- Num_of_Loan: integer (nullable = true)\n",
      " |-- Type_of_Loan: string (nullable = true)\n",
      " |-- Delay_from_due_date: integer (nullable = true)\n",
      " |-- Num_of_Delayed_Payment: integer (nullable = true)\n",
      " |-- Changed_Credit_Limit: integer (nullable = true)\n",
      " |-- Num_Credit_Inquiries: integer (nullable = true)\n",
      " |-- Credit_Mix: string (nullable = true)\n",
      " |-- Outstanding_Debt: double (nullable = true)\n",
      " |-- Credit_Utilization_Ratio: double (nullable = true)\n",
      " |-- Credit_History_Age: double (nullable = true)\n",
      " |-- Payment_of_Min_Amount: string (nullable = true)\n",
      " |-- Total_EMI_per_month: double (nullable = true)\n",
      " |-- Amount_invested_monthly: double (nullable = true)\n",
      " |-- Payment_Behaviour: string (nullable = true)\n",
      " |-- Monthly_Balance: double (nullable = true)\n",
      " |-- Type_of_Loan_clean: string (nullable = true)\n",
      " |-- fe_1: integer (nullable = true)\n",
      " |-- fe_2: integer (nullable = true)\n",
      " |-- fe_3: integer (nullable = true)\n",
      " |-- fe_4: integer (nullable = true)\n",
      " |-- fe_5: integer (nullable = true)\n",
      " |-- fe_6: integer (nullable = true)\n",
      " |-- fe_7: integer (nullable = true)\n",
      " |-- fe_8: integer (nullable = true)\n",
      " |-- fe_9: integer (nullable = true)\n",
      " |-- fe_10: integer (nullable = true)\n",
      " |-- fe_11: integer (nullable = true)\n",
      " |-- fe_12: integer (nullable = true)\n",
      " |-- fe_13: integer (nullable = true)\n",
      " |-- fe_14: integer (nullable = true)\n",
      " |-- fe_15: integer (nullable = true)\n",
      " |-- fe_16: integer (nullable = true)\n",
      " |-- fe_17: integer (nullable = true)\n",
      " |-- fe_18: integer (nullable = true)\n",
      " |-- fe_19: integer (nullable = true)\n",
      " |-- fe_20: integer (nullable = true)\n",
      " |-- total_loan_amount: long (nullable = true)\n",
      " |-- avg_overdue_amt: double (nullable = true)\n",
      " |-- max_balance: double (nullable = true)\n",
      " |-- num_installments: long (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/19 21:14:38 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer_ID</th>\n",
       "      <th>snapshot_date</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>SSN</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Annual_Income</th>\n",
       "      <th>Monthly_Inhand_Salary</th>\n",
       "      <th>Num_Bank_Accounts</th>\n",
       "      <th>Num_Credit_Card</th>\n",
       "      <th>...</th>\n",
       "      <th>fe_15</th>\n",
       "      <th>fe_16</th>\n",
       "      <th>fe_17</th>\n",
       "      <th>fe_18</th>\n",
       "      <th>fe_19</th>\n",
       "      <th>fe_20</th>\n",
       "      <th>total_loan_amount</th>\n",
       "      <th>avg_overdue_amt</th>\n",
       "      <th>max_balance</th>\n",
       "      <th>num_installments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CUS_0x1329</td>\n",
       "      <td>2023-06-01</td>\n",
       "      <td>Richarda</td>\n",
       "      <td>50</td>\n",
       "      <td>525-33-6734</td>\n",
       "      <td>Entrepreneur</td>\n",
       "      <td>160573.560</td>\n",
       "      <td>13293.130000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>71.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CUS_0x15df</td>\n",
       "      <td>2024-12-01</td>\n",
       "      <td>Whiteb</td>\n",
       "      <td>29</td>\n",
       "      <td>472-10-4696</td>\n",
       "      <td>Manager</td>\n",
       "      <td>162713.280</td>\n",
       "      <td>13672.440000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CUS_0x1a2f</td>\n",
       "      <td>2023-06-01</td>\n",
       "      <td>Lorrainey</td>\n",
       "      <td>54</td>\n",
       "      <td>894-09-8608</td>\n",
       "      <td>Journalist</td>\n",
       "      <td>152340.560</td>\n",
       "      <td>12568.046667</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>36.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-83.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CUS_0x1a5a</td>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>Petes</td>\n",
       "      <td>36</td>\n",
       "      <td>225-82-5288</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>32485.420</td>\n",
       "      <td>2451.118333</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>120.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>-67.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CUS_0x1cf3</td>\n",
       "      <td>2023-05-01</td>\n",
       "      <td>Henryc</td>\n",
       "      <td>38</td>\n",
       "      <td>229-46-4057</td>\n",
       "      <td>Manager</td>\n",
       "      <td>66858.270</td>\n",
       "      <td>5770.522500</td>\n",
       "      <td>3</td>\n",
       "      <td>541</td>\n",
       "      <td>...</td>\n",
       "      <td>-59.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CUS_0x1f15</td>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>Deepa Seetharamanh</td>\n",
       "      <td>19</td>\n",
       "      <td>296-58-9430</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>73378.320</td>\n",
       "      <td>5832.860000</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CUS_0x2452</td>\n",
       "      <td>2024-05-01</td>\n",
       "      <td>Juccak</td>\n",
       "      <td>17</td>\n",
       "      <td>144-82-6902</td>\n",
       "      <td>_______</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5626.853333</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>275.0</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>-94.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CUS_0x261d</td>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>Kirstin Ridleyg</td>\n",
       "      <td>17</td>\n",
       "      <td>897-84-1025</td>\n",
       "      <td>Architect</td>\n",
       "      <td>8400.715</td>\n",
       "      <td>418.059583</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>-36.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CUS_0x2ab3</td>\n",
       "      <td>2023-06-01</td>\n",
       "      <td>Steveng</td>\n",
       "      <td>16</td>\n",
       "      <td>928-63-7229</td>\n",
       "      <td>Musician</td>\n",
       "      <td>35891.330</td>\n",
       "      <td>2936.170717</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CUS_0x2b58</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>Annn</td>\n",
       "      <td>33</td>\n",
       "      <td>571-37-0616</td>\n",
       "      <td>Doctor</td>\n",
       "      <td>35479.470</td>\n",
       "      <td>2927.622500</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CUS_0x2f9d</td>\n",
       "      <td>2024-11-01</td>\n",
       "      <td>Angela Moone</td>\n",
       "      <td>5422</td>\n",
       "      <td>049-42-3355</td>\n",
       "      <td>Manager</td>\n",
       "      <td>7555.450</td>\n",
       "      <td>769.620833</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CUS_0x3acd</td>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>Laurencee</td>\n",
       "      <td>40</td>\n",
       "      <td>953-94-3809</td>\n",
       "      <td>Entrepreneur</td>\n",
       "      <td>49211.160</td>\n",
       "      <td>4048.930000</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>131.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>-77.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CUS_0x44d5</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>Jessica Toonkeld</td>\n",
       "      <td>40</td>\n",
       "      <td>103-44-2996</td>\n",
       "      <td>_______</td>\n",
       "      <td>9598.380</td>\n",
       "      <td>515.865000</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>297.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CUS_0x4798</td>\n",
       "      <td>2023-11-01</td>\n",
       "      <td>Prodhane</td>\n",
       "      <td>36</td>\n",
       "      <td>265-88-4094</td>\n",
       "      <td>Accountant</td>\n",
       "      <td>43287.280</td>\n",
       "      <td>3839.273333</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>131.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CUS_0x4af2</td>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>Tim Hepherw</td>\n",
       "      <td>45</td>\n",
       "      <td>129-44-0183</td>\n",
       "      <td>Media_Manager</td>\n",
       "      <td>76208.520</td>\n",
       "      <td>6431.710000</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>209.0</td>\n",
       "      <td>-37.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>-153.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CUS_0x4e94</td>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>Katyaq</td>\n",
       "      <td>47</td>\n",
       "      <td>936-14-9340</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>38533.760</td>\n",
       "      <td>3412.146667</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>-49.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CUS_0x4fac</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>Taras</td>\n",
       "      <td>44</td>\n",
       "      <td>339-46-1689</td>\n",
       "      <td>Scientist</td>\n",
       "      <td>0.000</td>\n",
       "      <td>10248.626667</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>140.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>-72.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CUS_0x5105</td>\n",
       "      <td>2024-11-01</td>\n",
       "      <td>Forgionex</td>\n",
       "      <td>51</td>\n",
       "      <td>834-61-1097</td>\n",
       "      <td>Mechanic</td>\n",
       "      <td>80191.380</td>\n",
       "      <td>6293.827869</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CUS_0x514e</td>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>Clara Ferreira-Marquesb</td>\n",
       "      <td>24</td>\n",
       "      <td>418-27-3029</td>\n",
       "      <td>Teacher</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1033.626667</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>CUS_0x56f9</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>Dis</td>\n",
       "      <td>37</td>\n",
       "      <td>502-99-8860</td>\n",
       "      <td>Doctor</td>\n",
       "      <td>34733.440</td>\n",
       "      <td>3163.453333</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>-76.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Customer_ID snapshot_date                     Name   Age          SSN  \\\n",
       "0   CUS_0x1329    2023-06-01                 Richarda    50  525-33-6734   \n",
       "1   CUS_0x15df    2024-12-01                   Whiteb    29  472-10-4696   \n",
       "2   CUS_0x1a2f    2023-06-01                Lorrainey    54  894-09-8608   \n",
       "3   CUS_0x1a5a    2024-04-01                    Petes    36  225-82-5288   \n",
       "4   CUS_0x1cf3    2023-05-01                   Henryc    38  229-46-4057   \n",
       "5   CUS_0x1f15    2025-01-01       Deepa Seetharamanh    19  296-58-9430   \n",
       "6   CUS_0x2452    2024-05-01                   Juccak    17  144-82-6902   \n",
       "7   CUS_0x261d    2023-12-01          Kirstin Ridleyg    17  897-84-1025   \n",
       "8   CUS_0x2ab3    2023-06-01                  Steveng    16  928-63-7229   \n",
       "9   CUS_0x2b58    2023-08-01                     Annn    33  571-37-0616   \n",
       "10  CUS_0x2f9d    2024-11-01             Angela Moone  5422  049-42-3355   \n",
       "11  CUS_0x3acd    2023-09-01                Laurencee    40  953-94-3809   \n",
       "12  CUS_0x44d5    2023-01-01         Jessica Toonkeld    40  103-44-2996   \n",
       "13  CUS_0x4798    2023-11-01                 Prodhane    36  265-88-4094   \n",
       "14  CUS_0x4af2    2023-12-01              Tim Hepherw    45  129-44-0183   \n",
       "15  CUS_0x4e94    2023-12-01                   Katyaq    47  936-14-9340   \n",
       "16  CUS_0x4fac    2023-08-01                    Taras    44  339-46-1689   \n",
       "17  CUS_0x5105    2024-11-01                Forgionex    51  834-61-1097   \n",
       "18  CUS_0x514e    2024-04-01  Clara Ferreira-Marquesb    24  418-27-3029   \n",
       "19  CUS_0x56f9    2023-08-01                      Dis    37  502-99-8860   \n",
       "\n",
       "       Occupation  Annual_Income  Monthly_Inhand_Salary  Num_Bank_Accounts  \\\n",
       "0    Entrepreneur     160573.560           13293.130000                  1   \n",
       "1         Manager     162713.280           13672.440000                  2   \n",
       "2      Journalist     152340.560           12568.046667                  5   \n",
       "3          Lawyer      32485.420            2451.118333                  3   \n",
       "4         Manager      66858.270            5770.522500                  3   \n",
       "5        Engineer      73378.320            5832.860000                  7   \n",
       "6         _______          0.000            5626.853333                  4   \n",
       "7       Architect       8400.715             418.059583                  8   \n",
       "8        Musician      35891.330            2936.170717                  5   \n",
       "9          Doctor      35479.470            2927.622500                  5   \n",
       "10        Manager       7555.450             769.620833                  8   \n",
       "11   Entrepreneur      49211.160            4048.930000                  4   \n",
       "12        _______       9598.380             515.865000                  7   \n",
       "13     Accountant      43287.280            3839.273333                  7   \n",
       "14  Media_Manager      76208.520            6431.710000                  5   \n",
       "15       Engineer      38533.760            3412.146667                  4   \n",
       "16      Scientist          0.000           10248.626667                  5   \n",
       "17       Mechanic      80191.380            6293.827869                  2   \n",
       "18        Teacher          0.000            1033.626667                 10   \n",
       "19         Doctor      34733.440            3163.453333                  3   \n",
       "\n",
       "    Num_Credit_Card  ...  fe_15  fe_16  fe_17  fe_18  fe_19  fe_20  \\\n",
       "0                 2  ...   71.0  114.0   29.0  193.0  242.0  218.0   \n",
       "1                 3  ...    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "2                 4  ...   36.0  105.0  180.0  -17.0   15.0  -83.0   \n",
       "3                 6  ...  120.0   -4.0  -28.0   23.0  -67.0  111.0   \n",
       "4               541  ...  -59.0   36.0  -10.0  233.0  205.0   44.0   \n",
       "5                 8  ...    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "6                 7  ...  275.0  -35.0  -94.0  185.0   87.0  151.0   \n",
       "7                10  ...   -7.0  108.0  165.0  -36.0   90.0  127.0   \n",
       "8                 4  ...   14.0  189.0  127.0   56.0  167.0  -28.0   \n",
       "9                 3  ...   12.0  106.0  204.0  221.0  109.0  241.0   \n",
       "10                6  ...    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "11                5  ...  131.0   89.0   38.0  151.0  -77.0   34.0   \n",
       "12                6  ...  297.0   68.0  120.0   33.0   -1.0   25.0   \n",
       "13                6  ...  131.0   72.0  111.0  215.0  -25.0  137.0   \n",
       "14                7  ...  209.0  -37.0  205.0   43.0 -153.0  120.0   \n",
       "15                3  ...  -49.0  145.0   59.0  163.0  215.0  155.0   \n",
       "16                5  ...  140.0    6.0  121.0  -72.0  211.0  111.0   \n",
       "17                3  ...    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "18                7  ...    3.0   29.0  130.0   -7.0   70.0   90.0   \n",
       "19                7  ...  -30.0  105.0   74.0  123.0  -76.0  210.0   \n",
       "\n",
       "    total_loan_amount avg_overdue_amt  max_balance  num_installments  \n",
       "0               10000             0.0      10000.0                 1  \n",
       "1               10000             0.0      10000.0                 1  \n",
       "2               10000             0.0      10000.0                 1  \n",
       "3               10000             0.0      10000.0                 1  \n",
       "4               10000             0.0      10000.0                 1  \n",
       "5               10000             0.0      10000.0                 1  \n",
       "6               10000             0.0      10000.0                 1  \n",
       "7               10000             0.0      10000.0                 1  \n",
       "8               10000             0.0      10000.0                 1  \n",
       "9               10000             0.0      10000.0                 1  \n",
       "10              10000             0.0      10000.0                 1  \n",
       "11              10000             0.0      10000.0                 1  \n",
       "12              10000             0.0      10000.0                 1  \n",
       "13              10000             0.0      10000.0                 1  \n",
       "14              10000             0.0      10000.0                 1  \n",
       "15              10000             0.0      10000.0                 1  \n",
       "16              10000             0.0      10000.0                 1  \n",
       "17              10000             0.0      10000.0                 1  \n",
       "18              10000             0.0      10000.0                 1  \n",
       "19              10000             0.0      10000.0                 1  \n",
       "\n",
       "[20 rows x 51 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"SilverEDA\").getOrCreate()\n",
    "\n",
    "silver = spark.read.parquet(\"/Users/shwe/Desktop/assignment_1_mle/datamart/silver/feature_store\")\n",
    "silver.printSchema()\n",
    "# Convert just 20 rows to pandas for nicer display:\n",
    "silver.limit(20).toPandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "86b71578",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/19 22:05:10 ERROR Executor: Exception in task 0.0 in stage 64.0 (TID 44)\n",
      "org.apache.spark.SparkFileNotFoundException: File file:/Users/shwe/Desktop/assignment_1_mle/datamart/silver/feature_store/part-00000-dbd0f696-1aee-4ec8-93d6-6be6f918e74b-c000.snappy.parquet does not exist\n",
      "It is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.\n",
      "\tat org.apache.spark.sql.errors.QueryExecutionErrors$.readCurrentFileNotFoundError(QueryExecutionErrors.scala:781)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:222)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:282)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:131)\n",
      "\tat org.apache.spark.sql.execution.FileSourceScanExec$$anon$1.hasNext(DataSourceScanExec.scala:593)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.columnartorow_nextBatch_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.hashAgg_doAggregateWithKeys_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:140)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "25/05/19 22:05:10 WARN TaskSetManager: Lost task 0.0 in stage 64.0 (TID 44) (192.168.18.3 executor driver): org.apache.spark.SparkFileNotFoundException: File file:/Users/shwe/Desktop/assignment_1_mle/datamart/silver/feature_store/part-00000-dbd0f696-1aee-4ec8-93d6-6be6f918e74b-c000.snappy.parquet does not exist\n",
      "It is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.\n",
      "\tat org.apache.spark.sql.errors.QueryExecutionErrors$.readCurrentFileNotFoundError(QueryExecutionErrors.scala:781)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:222)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:282)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:131)\n",
      "\tat org.apache.spark.sql.execution.FileSourceScanExec$$anon$1.hasNext(DataSourceScanExec.scala:593)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.columnartorow_nextBatch_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.hashAgg_doAggregateWithKeys_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:140)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "\n",
      "25/05/19 22:05:10 ERROR TaskSetManager: Task 0 in stage 64.0 failed 1 times; aborting job\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o112.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 64.0 failed 1 times, most recent failure: Lost task 0.0 in stage 64.0 (TID 44) (192.168.18.3 executor driver): org.apache.spark.SparkFileNotFoundException: File file:/Users/shwe/Desktop/assignment_1_mle/datamart/silver/feature_store/part-00000-dbd0f696-1aee-4ec8-93d6-6be6f918e74b-c000.snappy.parquet does not exist\nIt is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.readCurrentFileNotFoundError(QueryExecutionErrors.scala:781)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:222)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:282)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:131)\n\tat org.apache.spark.sql.execution.FileSourceScanExec$$anon$1.hasNext(DataSourceScanExec.scala:593)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.columnartorow_nextBatch_0$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.hashAgg_doAggregateWithKeys_0$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:140)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\nCaused by: org.apache.spark.SparkFileNotFoundException: File file:/Users/shwe/Desktop/assignment_1_mle/datamart/silver/feature_store/part-00000-dbd0f696-1aee-4ec8-93d6-6be6f918e74b-c000.snappy.parquet does not exist\nIt is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.readCurrentFileNotFoundError(QueryExecutionErrors.scala:781)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:222)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:282)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:131)\n\tat org.apache.spark.sql.execution.FileSourceScanExec$$anon$1.hasNext(DataSourceScanExec.scala:593)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.columnartorow_nextBatch_0$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.hashAgg_doAggregateWithKeys_0$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:140)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 17\u001b[0m\n\u001b[1;32m      5\u001b[0m result \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39msql(\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124m  SELECT\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124m    Age,\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124m  ORDER BY Age DESC\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# 3. Show the top results\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m result\u001b[38;5;241m.\u001b[39mshow(\u001b[38;5;241m10\u001b[39m, truncate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pyspark/sql/dataframe.py:947\u001b[0m, in \u001b[0;36mDataFrame.show\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mshow\u001b[39m(\u001b[38;5;28mself\u001b[39m, n: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m, truncate: Union[\u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, vertical: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    888\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Prints the first ``n`` rows to the console.\u001b[39;00m\n\u001b[1;32m    889\u001b[0m \n\u001b[1;32m    890\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    945\u001b[0m \u001b[38;5;124;03m    name | Bob\u001b[39;00m\n\u001b[1;32m    946\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_show_string(n, truncate, vertical))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pyspark/sql/dataframe.py:978\u001b[0m, in \u001b[0;36mDataFrame._show_string\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    969\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m    970\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[1;32m    971\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT_BOOL\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    972\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    975\u001b[0m         },\n\u001b[1;32m    976\u001b[0m     )\n\u001b[0;32m--> 978\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jdf\u001b[38;5;241m.\u001b[39mshowString(n, int_truncate, vertical)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pyspark/errors/exceptions/captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o112.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 64.0 failed 1 times, most recent failure: Lost task 0.0 in stage 64.0 (TID 44) (192.168.18.3 executor driver): org.apache.spark.SparkFileNotFoundException: File file:/Users/shwe/Desktop/assignment_1_mle/datamart/silver/feature_store/part-00000-dbd0f696-1aee-4ec8-93d6-6be6f918e74b-c000.snappy.parquet does not exist\nIt is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.readCurrentFileNotFoundError(QueryExecutionErrors.scala:781)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:222)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:282)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:131)\n\tat org.apache.spark.sql.execution.FileSourceScanExec$$anon$1.hasNext(DataSourceScanExec.scala:593)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.columnartorow_nextBatch_0$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.hashAgg_doAggregateWithKeys_0$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:140)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\nCaused by: org.apache.spark.SparkFileNotFoundException: File file:/Users/shwe/Desktop/assignment_1_mle/datamart/silver/feature_store/part-00000-dbd0f696-1aee-4ec8-93d6-6be6f918e74b-c000.snappy.parquet does not exist\nIt is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.readCurrentFileNotFoundError(QueryExecutionErrors.scala:781)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:222)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:282)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:131)\n\tat org.apache.spark.sql.execution.FileSourceScanExec$$anon$1.hasNext(DataSourceScanExec.scala:593)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.columnartorow_nextBatch_0$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.hashAgg_doAggregateWithKeys_0$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:140)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\n"
     ]
    }
   ],
   "source": [
    "# 1. Register the DataFrame as a temporary view\n",
    "silver.createOrReplaceTempView(\"silver_view\")\n",
    "\n",
    "# 2. Run any SQL you like\n",
    "result = spark.sql(\"\"\"\n",
    "  SELECT\n",
    "    Age,\n",
    "    COUNT(*)          AS n_users,\n",
    "    ROUND(AVG(Annual_Income), 2) AS avg_income\n",
    "  FROM silver_view\n",
    "  WHERE Age BETWEEN 18 AND 65\n",
    "  GROUP BY Age\n",
    "  ORDER BY Age DESC\n",
    "\"\"\")\n",
    "\n",
    "# 3. Show the top results\n",
    "result.show(10, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "678b4ef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In your notebook, before running your query again:\n",
    "spark.sql(\"REFRESH TABLE silver_view\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "32a49be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+\n",
      "|snapshot_date|n_records|\n",
      "+-------------+---------+\n",
      "|2023-01-01   |530      |\n",
      "|2023-02-01   |501      |\n",
      "|2023-03-01   |506      |\n",
      "|2023-04-01   |510      |\n",
      "|2023-05-01   |521      |\n",
      "|2023-06-01   |517      |\n",
      "|2023-07-01   |471      |\n",
      "|2023-08-01   |481      |\n",
      "|2023-09-01   |454      |\n",
      "|2023-10-01   |487      |\n",
      "|2023-11-01   |491      |\n",
      "|2023-12-01   |489      |\n",
      "|2024-01-01   |485      |\n",
      "|2024-02-01   |518      |\n",
      "|2024-03-01   |511      |\n",
      "|2024-04-01   |513      |\n",
      "|2024-05-01   |491      |\n",
      "|2024-06-01   |498      |\n",
      "|2024-07-01   |505      |\n",
      "|2024-08-01   |543      |\n",
      "+-------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# How many records per snapshot_date?\n",
    "spark.sql(\"\"\"\n",
    "  SELECT snapshot_date,\n",
    "         COUNT(*) AS n_records\n",
    "  FROM silver_view\n",
    "  GROUP BY snapshot_date\n",
    "  ORDER BY snapshot_date\n",
    "\"\"\").show(20, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8815e0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+\n",
      "|Age|n_users|\n",
      "+---+-------+\n",
      "|-1 |637    |\n",
      "|26 |364    |\n",
      "|35 |361    |\n",
      "|39 |360    |\n",
      "|32 |360    |\n",
      "|38 |345    |\n",
      "|28 |343    |\n",
      "|44 |343    |\n",
      "|20 |342    |\n",
      "|41 |340    |\n",
      "|25 |340    |\n",
      "|36 |339    |\n",
      "|31 |336    |\n",
      "|19 |336    |\n",
      "|29 |336    |\n",
      "|37 |333    |\n",
      "|30 |330    |\n",
      "|27 |326    |\n",
      "|22 |326    |\n",
      "|34 |325    |\n",
      "+---+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Which ages are most common?\n",
    "spark.sql(\"\"\"\n",
    "  SELECT Age,\n",
    "         COUNT(*) AS n_users\n",
    "  FROM silver_view\n",
    "  GROUP BY Age\n",
    "  ORDER BY n_users DESC\n",
    "\"\"\").show(20, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a68266a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---+\n",
      "|Occupation   |cnt|\n",
      "+-------------+---+\n",
      "|unknown      |880|\n",
      "|Lawyer       |828|\n",
      "|Architect    |795|\n",
      "|Engineer     |793|\n",
      "|Accountant   |791|\n",
      "|Scientist    |789|\n",
      "|Teacher      |782|\n",
      "|Media_Manager|780|\n",
      "|Developer    |780|\n",
      "|Mechanic     |780|\n",
      "|Entrepreneur |776|\n",
      "|Journalist   |761|\n",
      "|Doctor       |760|\n",
      "|Musician     |741|\n",
      "|Manager      |736|\n",
      "|Writer       |728|\n",
      "+-------------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dominant job categories.\n",
    "spark.sql(\"\"\"\n",
    "  SELECT Occupation,\n",
    "         COUNT(*) AS cnt\n",
    "  FROM silver_view\n",
    "  GROUP BY Occupation\n",
    "  ORDER BY cnt DESC\n",
    "\"\"\").show(20, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5f683a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+----+\n",
      "|Type_of_Loan_clean     |cnt |\n",
      "+-----------------------+----+\n",
      "|Multiple               |9683|\n",
      "|Unknown                |1602|\n",
      "|Credit-builder Loan    |160 |\n",
      "|Personal Loan          |159 |\n",
      "|Debt Consolidation Loan|158 |\n",
      "|Student Loan           |155 |\n",
      "|Payday Loan            |150 |\n",
      "|Mortgage Loan          |147 |\n",
      "|Auto Loan              |144 |\n",
      "|Home Equity Loan       |142 |\n",
      "+-----------------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# How do users split across “Unknown”, “Multiple”, and each loan?\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "  SELECT Type_of_Loan_clean,\n",
    "         COUNT(*) AS cnt\n",
    "  FROM silver_view\n",
    "  GROUP BY Type_of_Loan_clean\n",
    "  ORDER BY cnt DESC\n",
    "\"\"\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "689e9d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+----+\n",
      "|Credit_Mix|avg_util|cnt |\n",
      "+----------+--------+----+\n",
      "|Good      |32.97   |3032|\n",
      "|unknown   |32.29   |2611|\n",
      "|Standard  |32.26   |4497|\n",
      "|Bad       |31.79   |2360|\n",
      "+----------+--------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# How does credit utilization vary by Credit_Mix?\n",
    "spark.sql(\"\"\"\n",
    "  SELECT Credit_Mix,\n",
    "         ROUND(AVG(Credit_Utilization_Ratio),2) AS avg_util,\n",
    "         COUNT(*)                        AS cnt\n",
    "  FROM silver_view\n",
    "  GROUP BY Credit_Mix\n",
    "  ORDER BY avg_util DESC\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f8922a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+\n",
      "|avg_fe1|avg_fe2|avg_fe3|avg_fe4|avg_fe5|\n",
      "+-------+-------+-------+-------+-------+\n",
      "|103.06 |103.23 |103.83 |105.33 |107.04 |\n",
      "+-------+-------+-------+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Clickstream signal overview\n",
    "spark.sql(\"\"\"\n",
    "  SELECT\n",
    "    ROUND(AVG(fe_1),2)  AS avg_fe1,\n",
    "    ROUND(AVG(fe_2),2)  AS avg_fe2,\n",
    "    ROUND(AVG(fe_3),2)  AS avg_fe3,\n",
    "    ROUND(AVG(fe_4),2)  AS avg_fe4,\n",
    "    ROUND(AVG(fe_5),2)  AS avg_fe5\n",
    "  FROM silver_view\n",
    "\"\"\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2599c082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload & register\n",
    "silver = spark.read.parquet(\"/Users/shwe/Desktop/assignment_1_mle/datamart/silver/feature_store\")\n",
    "silver.createOrReplaceTempView(\"silver_view\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "aebc57d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+---------------+----------------+--------------+\n",
      "|Age_null_pct|Occ_null_pct|Income_null_pct|LoanAmt_null_pct|Instl_null_pct|\n",
      "+------------+------------+---------------+----------------+--------------+\n",
      "|0.0         |0.0         |0.0            |0.0             |0.0           |\n",
      "+------------+------------+---------------+----------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "  SELECT\n",
    "    ROUND(100 * SUM(CASE WHEN Age              IS NULL THEN 1 ELSE 0 END) / COUNT(*), 2) AS Age_null_pct,\n",
    "    ROUND(100 * SUM(CASE WHEN Occupation       IS NULL THEN 1 ELSE 0 END) / COUNT(*), 2) AS Occ_null_pct,\n",
    "    ROUND(100 * SUM(CASE WHEN Annual_Income    IS NULL THEN 1 ELSE 0 END) / COUNT(*), 2) AS Income_null_pct,\n",
    "    ROUND(100 * SUM(CASE WHEN total_loan_amount IS NULL THEN 1 ELSE 0 END) / COUNT(*), 2) AS LoanAmt_null_pct,\n",
    "    ROUND(100 * SUM(CASE WHEN num_installments IS NULL THEN 1 ELSE 0 END) / COUNT(*), 2) AS Instl_null_pct\n",
    "  FROM silver_view\n",
    "\"\"\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "69246a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------+-------------------------------------------------------+-------------------------------------------------+---------------------+------+\n",
      "|income_q                                                      |debt_q                                                 |loan_q                                           |instl_q              |hist_q|\n",
      "+--------------------------------------------------------------+-------------------------------------------------------+-------------------------------------------------+---------------------+------+\n",
      "|[0.0, 0.0, 17442.09, 34838.94, 70088.36, 132398.13, 177907.72]|[0.0, 91.91, 550.67, 1151.7, 1933.58, 4070.33, 4799.54]|[10000, 10000, 10000, 10000, 10000, 10000, 10000]|[1, 1, 1, 1, 1, 1, 1]|NULL  |\n",
      "+--------------------------------------------------------------+-------------------------------------------------------+-------------------------------------------------+---------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "  SELECT\n",
    "    percentile_approx(Annual_Income,       array(0.01,0.05,0.25,0.5,0.75,0.95,0.99)) AS income_q,\n",
    "    percentile_approx(Outstanding_Debt,    array(0.01,0.05,0.25,0.5,0.75,0.95,0.99)) AS debt_q,\n",
    "    percentile_approx(total_loan_amount,   array(0.01,0.05,0.25,0.5,0.75,0.95,0.99)) AS loan_q,\n",
    "    percentile_approx(num_installments,    array(0.01,0.05,0.25,0.5,0.75,0.95,0.99)) AS instl_q,\n",
    "    percentile_approx(Credit_History_Age,  array(0.01,0.05,0.25,0.5,0.75,0.95,0.99)) AS hist_q\n",
    "  FROM silver_view\n",
    "\"\"\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9c6b42d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+-----------------+-------------------+\n",
      "|corr_inc_debt       |corr_inc_loan|corr_loan_overdue|corr_beh_debt      |\n",
      "+--------------------+-------------+-----------------+-------------------+\n",
      "|-0.01537526479056011|NULL         |NULL             |0.03812338725809156|\n",
      "+--------------------+-------------+-----------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "  SELECT\n",
    "    corr(Annual_Income, Outstanding_Debt)     AS corr_inc_debt,\n",
    "    corr(Annual_Income, total_loan_amount)    AS corr_inc_loan,\n",
    "    corr(total_loan_amount, avg_overdue_amt)  AS corr_loan_overdue,\n",
    "    corr(fe_1 + fe_2 + fe_3 + fe_4 + fe_5, Outstanding_Debt) AS corr_beh_debt\n",
    "  FROM silver_view\n",
    "\"\"\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0b0c420b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+-----------+--------+-----------+\n",
      "|total_users|zero_inst|any_overdue|avg_inst|avg_overdue|\n",
      "+-----------+---------+-----------+--------+-----------+\n",
      "|12500      |0        |0          |1.0     |0.0        |\n",
      "+-----------+---------+-----------+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "  SELECT\n",
    "    COUNT(*) AS total_users,\n",
    "    SUM(CASE WHEN num_installments = 0 THEN 1 ELSE 0 END) AS zero_inst,\n",
    "    SUM(CASE WHEN avg_overdue_amt > 0 THEN 1 ELSE 0 END)    AS any_overdue,\n",
    "    ROUND(AVG(num_installments),2)                         AS avg_inst,\n",
    "    ROUND(AVG(avg_overdue_amt),2)                          AS avg_overdue\n",
    "  FROM silver_view\n",
    "\"\"\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "403ab471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+--------+\n",
      "|hist_bucket|cnt  |avg_debt|\n",
      "+-----------+-----+--------+\n",
      "|5+yr       |12500|1411.21 |\n",
      "+-----------+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "  SELECT\n",
    "    CASE\n",
    "      WHEN Credit_History_Age < 1  THEN '<1yr'\n",
    "      WHEN Credit_History_Age < 3  THEN '1-3yr'\n",
    "      WHEN Credit_History_Age < 5  THEN '3-5yr'\n",
    "      ELSE '5+yr'\n",
    "    END AS hist_bucket,\n",
    "    COUNT(*) AS cnt,\n",
    "    ROUND(AVG(Outstanding_Debt),2) AS avg_debt\n",
    "  FROM silver_view\n",
    "  GROUP BY hist_bucket\n",
    "  ORDER BY cnt DESC\n",
    "\"\"\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4a48b5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+--------+\n",
      "|min_hist|quantiles|max_hist|\n",
      "+--------+---------+--------+\n",
      "|NULL    |NULL     |NULL    |\n",
      "+--------+---------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "spark.sql(\"\"\"\n",
    "  SELECT\n",
    "    MIN(Credit_History_Age)   AS min_hist,\n",
    "    percentile_approx(Credit_History_Age, array(0.10,0.25,0.50,0.75,0.90)) AS quantiles,\n",
    "    MAX(Credit_History_Age)   AS max_hist\n",
    "  FROM silver_view\n",
    "\"\"\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "deb5d13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n",
      "|Credit_History_Age    |\n",
      "+----------------------+\n",
      "|0 Years and 10 Months |\n",
      "|0 Years and 11 Months |\n",
      "|0 Years and 8 Months  |\n",
      "|0 Years and 9 Months  |\n",
      "|1 Years and 0 Months  |\n",
      "|1 Years and 10 Months |\n",
      "|1 Years and 11 Months |\n",
      "|1 Years and 2 Months  |\n",
      "|1 Years and 3 Months  |\n",
      "|1 Years and 4 Months  |\n",
      "|1 Years and 5 Months  |\n",
      "|1 Years and 6 Months  |\n",
      "|1 Years and 7 Months  |\n",
      "|1 Years and 8 Months  |\n",
      "|1 Years and 9 Months  |\n",
      "|10 Years and 0 Months |\n",
      "|10 Years and 1 Months |\n",
      "|10 Years and 10 Months|\n",
      "|10 Years and 11 Months|\n",
      "|10 Years and 2 Months |\n",
      "|10 Years and 3 Months |\n",
      "|10 Years and 4 Months |\n",
      "|10 Years and 5 Months |\n",
      "|10 Years and 6 Months |\n",
      "|10 Years and 7 Months |\n",
      "|10 Years and 8 Months |\n",
      "|10 Years and 9 Months |\n",
      "|11 Years and 0 Months |\n",
      "|11 Years and 1 Months |\n",
      "|11 Years and 10 Months|\n",
      "|11 Years and 11 Months|\n",
      "|11 Years and 2 Months |\n",
      "|11 Years and 3 Months |\n",
      "|11 Years and 4 Months |\n",
      "|11 Years and 5 Months |\n",
      "|11 Years and 6 Months |\n",
      "|11 Years and 7 Months |\n",
      "|11 Years and 8 Months |\n",
      "|11 Years and 9 Months |\n",
      "|12 Years and 0 Months |\n",
      "|12 Years and 1 Months |\n",
      "|12 Years and 10 Months|\n",
      "|12 Years and 11 Months|\n",
      "|12 Years and 2 Months |\n",
      "|12 Years and 3 Months |\n",
      "|12 Years and 4 Months |\n",
      "|12 Years and 5 Months |\n",
      "|12 Years and 6 Months |\n",
      "|12 Years and 7 Months |\n",
      "|12 Years and 8 Months |\n",
      "+----------------------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1) Load the raw financials CSV\n",
    "raw_fin = spark.read \\\n",
    "    .option(\"header\", True) \\\n",
    "    .csv(\"/Users/shwe/Desktop/assignment_1_mle/data/features_financials.csv\")\n",
    "\n",
    "# 2) See all distinct Credit_History_Age strings\n",
    "raw_fin.select(\"Credit_History_Age\") \\\n",
    "       .distinct() \\\n",
    "       .orderBy(\"Credit_History_Age\") \\\n",
    "       .show(50, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "83c3e91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Read the updated Silver parquet\n",
    "silver = spark.read.parquet(\"/Users/shwe/Desktop/assignment_1_mle/datamart/silver/feature_store\")\n",
    "\n",
    "# 2. (Re)create the SQL view\n",
    "silver.createOrReplaceTempView(\"silver_view\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3e7454bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------------------------------------------------------------+------------------+\n",
      "|min_hist          |hist_quantiles                                                          |max_hist          |\n",
      "+------------------+------------------------------------------------------------------------+------------------+\n",
      "|0.6666666666666666|[7.25, 12.333333333333334, 18.5, 25.416666666666668, 30.416666666666668]|33.666666666666664|\n",
      "+------------------+------------------------------------------------------------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "  SELECT\n",
    "    MIN(Credit_History_Age)   AS min_hist,\n",
    "    percentile_approx(Credit_History_Age, array(0.10,0.25,0.50,0.75,0.90)) AS hist_quantiles,\n",
    "    MAX(Credit_History_Age)   AS max_hist\n",
    "  FROM silver_view\n",
    "\"\"\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03d4258d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|total_rows|\n",
      "+----------+\n",
      "|     12500|\n",
      "+----------+\n",
      "\n",
      "+-----------+-------------+-----------+-----------+---------------------+-------------------+-------------------+---------+-----------+----------------+-----------+----+----+----+----+----+----+----+----+----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+---------+-----+------------+---------------------+-----------+------------------+----------+---------------------+--------------------------------+\n",
      "|Customer_ID|snapshot_date|Age_imputed|Age_missing|debt_to_income       |loan_to_income     |inquiry_per_year   |has_loans|has_overdue|high_utilization|session_sum|fe_1|fe_2|fe_3|fe_4|fe_5|fe_6|fe_7|fe_8|fe_9|fe_10|fe_11|fe_12|fe_13|fe_14|fe_15|fe_16|fe_17|fe_18|fe_19|fe_20|no_clicks|month|week_of_year|days_since_first_loan|hist_bucket|Type_of_Loan_clean|Credit_Mix|Payment_of_Min_Amount|Payment_Behaviour               |\n",
      "+-----------+-------------+-----------+-----------+---------------------+-------------------+-------------------+---------+-----------+----------------+-----------+----+----+----+----+----+----+----+----+----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+---------+-----+------------+---------------------+-----------+------------------+----------+---------------------+--------------------------------+\n",
      "|CUS_0x1000 |2023-05-01   |18.0       |0          |0.05103222954136099  |0.32652059006187806|1.0232558138583017 |1        |0          |0               |915        |58  |15  |18  |-101|48  |-33 |238 |119 |75  |52   |39   |131  |-34  |145  |-61  |39   |52   |80   |4    |31   |0        |5    |18          |0                    |<=25th     |Multiple          |Bad       |Yes                  |High_spent_Medium_value_payments|\n",
      "|CUS_0x1009 |2025-01-01   |26.0       |0          |2.0268E11            |1.0E13             |0.1290322580603538 |1        |0          |1               |0          |0   |0   |0   |0   |0   |0   |0   |0   |0   |0    |0    |0    |0    |0    |0    |0    |0    |0    |0    |0    |1        |1    |1           |0                    |>75th      |Multiple          |unknown   |Yes                  |High_spent_Medium_value_payments|\n",
      "|CUS_0x100b |2024-03-01   |19.0       |0          |0.009054204734183604 |0.08788783473290239|0.25263157893141275|1        |0          |0               |1704       |210 |129 |107 |118 |-51 |67  |40  |88  |189 |123  |125  |2    |60   |242  |177  |29   |-94  |-38  |380  |-199 |0        |3    |9           |0                    |25-50th    |Unknown           |Good      |No                   |High_spent_Small_value_payments |\n",
      "|CUS_0x1011 |2023-11-01   |44.0       |0          |0.008030418984063774 |0.16972606383023575|0.4421052631299723 |1        |0          |0               |2847       |142 |229 |121 |29  |278 |145 |309 |-52 |139 |94   |59   |97   |49   |99   |50   |173  |280  |138  |381  |87   |0        |11   |44          |0                    |25-50th    |Multiple          |Standard  |Yes                  |Low_spent_Medium_value_payments |\n",
      "|CUS_0x1013 |2023-12-01   |44.0       |0          |0.01250758205809745  |0.10139830287632406|0.16822429905598743|1        |0          |0               |1862       |61  |28  |237 |31  |2   |264 |110 |-19 |116 |207  |120  |-6   |121  |28   |-62  |189  |85   |69   |103  |178  |0        |12   |48          |0                    |25-50th    |Multiple          |Good      |No                   |High_spent_Medium_value_payments|\n",
      "|CUS_0x1015 |2023-08-01   |27.0       |0          |0.007246274947807158 |0.21298791804735634|0.42023346301539766|1        |0          |0               |2326       |-32 |203 |-32 |185 |163 |222 |172 |95  |142 |131  |257  |-35  |164  |-47  |237  |145  |158  |156  |36   |6    |0        |8    |31          |0                    |50-75th    |Unknown           |Standard  |NM                   |Low_spent_Small_value_payments  |\n",
      "|CUS_0x1018 |2023-11-01   |15.0       |0          |0.0453157710596692   |0.16341255083559925|0.5614035087325331 |1        |0          |0               |2596       |-16 |214 |212 |181 |131 |174 |-1  |249 |250 |125  |90   |119  |-66  |134  |169  |19   |230  |227  |138  |17   |0        |11   |44          |0                    |25-50th    |Multiple          |Bad       |Yes                  |High_spent_Medium_value_payments|\n",
      "|CUS_0x1026 |2023-10-01   |52.0       |0          |0.004980181025878931 |0.05861174105707882|0.1451612903155567 |1        |0          |0               |2063       |102 |-25 |-46 |144 |-59 |312 |102 |194 |116 |76   |30   |277  |75   |-14  |196  |259  |181  |78   |-10  |75   |0        |10   |39          |0                    |50-75th    |Multiple          |Good      |No                   |High_spent_Medium_value_payments|\n",
      "|CUS_0x102d |2024-01-01   |31.0       |0          |0.007279666471003186 |0.11227815520703291|0.0991735537157298 |1        |0          |0               |1364       |271 |66  |2   |226 |30  |86  |86  |-5  |-22 |-16  |136  |180  |-18  |162  |209  |-104 |-54  |72   |104  |-47  |0        |1    |1           |0                    |>75th      |Mortgage Loan     |unknown   |No                   |High_spent_Medium_value_payments|\n",
      "|CUS_0x102e |2024-04-01   |26.0       |0          |0.017115406719960362 |0.19682156786486002|0.1751824817441526 |1        |0          |0               |2210       |45  |27  |-42 |176 |137 |169 |165 |164 |110 |61   |133  |191  |90   |131  |52   |28   |19   |129  |266  |159  |0        |4    |14          |0                    |50-75th    |Multiple          |unknown   |NM                   |High_spent_Medium_value_payments|\n",
      "|CUS_0x1032 |2023-08-01   |32.0       |1          |0.030670934767774997 |0.16553293161801214|0.553846153812071  |1        |0          |0               |3009       |53  |128 |21  |144 |85  |266 |-41 |101 |329 |201  |185  |219  |240  |67   |383  |131  |140  |193  |166  |-2   |0        |8    |31          |0                    |25-50th    |Multiple          |Standard  |Yes                  |!@9#%8                          |\n",
      "|CUS_0x1037 |2023-01-01   |45.0       |0          |0.04164215775949395  |0.6254266582483847 |0.15189873416952412|1        |0          |1               |1118       |63  |118 |80  |121 |55  |193 |111 |112 |-101|83   |164  |105  |-16  |-81  |-126 |114  |35   |85   |-73  |76   |0        |1    |52          |0                    |50-75th    |Multiple          |Good      |No                   |Low_spent_Small_value_payments  |\n",
      "|CUS_0x1038 |2024-10-01   |28.0       |0          |0.004388631589744126 |0.07723608506967716|0.499999999975     |1        |0          |0               |0          |0   |0   |0   |0   |0   |0   |0   |0   |0   |0    |0    |0    |0    |0    |0    |0    |0    |0    |0    |0    |1        |10   |40          |0                    |50-75th    |Multiple          |Standard  |Yes                  |Low_spent_Medium_value_payments |\n",
      "|CUS_0x103e |2024-12-01   |40.0       |0          |0.0071633830103717145|0.1013265674206704 |0.14860681113998983|1        |0          |0               |0          |0   |0   |0   |0   |0   |0   |0   |0   |0   |0    |0    |0    |0    |0    |0    |0    |0    |0    |0    |0    |1        |12   |48          |0                    |>75th      |Student Loan      |Good      |No                   |Low_spent_Small_value_payments  |\n",
      "|CUS_0x1041 |2023-11-01   |15.0       |0          |0.5472365564689508   |1.1138201692782652 |0.95999999990784   |1        |0          |0               |1179       |-26 |147 |136 |-129|-40 |204 |48  |-183|120 |-31  |58   |34   |0    |215  |162  |135  |106  |219  |7    |-3   |0        |11   |44          |0                    |<=25th     |Multiple          |Bad       |Yes                  |High_spent_Small_value_payments |\n",
      "|CUS_0x1044 |2023-06-01   |44.0       |0          |0.004633750966984387 |0.29902884402325675|0.15665796344156685|1        |0          |0               |1289       |64  |-36 |-27 |254 |-142|31  |245 |96  |154 |-26  |32   |101  |63   |80   |146  |62   |66   |125  |40   |-39  |0        |6    |22          |0                    |>75th      |Unknown           |unknown   |No                   |Low_spent_Small_value_payments  |\n",
      "|CUS_0x1048 |2024-02-01   |27.0       |0          |0.04330683026191086  |0.2359183854500583 |0.69999999993      |1        |0          |0               |2648       |264 |137 |178 |279 |142 |222 |29  |131 |67  |97   |143  |353  |211  |156  |-139 |254  |40   |28   |151  |-95  |0        |2    |5           |0                    |<=25th     |Multiple          |Standard  |Yes                  |High_spent_Small_value_payments |\n",
      "|CUS_0x104a |2023-12-01   |37.0       |0          |0.07492362190690752  |0.6674948052216338 |0.12403100774809207|1        |0          |1               |1481       |27  |149 |194 |-125|75  |187 |120 |126 |268 |-166 |227  |-108 |202  |29   |70   |42   |52   |-25  |191  |-54  |0        |12   |48          |0                    |>75th      |Multiple          |Good      |No                   |Low_spent_Small_value_payments  |\n",
      "|CUS_0x104e |2023-06-01   |50.0       |0          |0.05878617601808162  |0.5213527853532962 |0.23841059601701678|1        |0          |0               |1882       |144 |-8  |18  |113 |135 |31  |189 |190 |-30 |-92  |19   |284  |-120 |101  |-61  |161  |143  |260  |208  |197  |0        |6    |22          |0                    |50-75th    |Multiple          |Standard  |No                   |High_spent_Small_value_payments |\n",
      "|CUS_0x104f |2024-10-01   |20.0       |0          |0.015699267035286683 |0.8820804042750131 |0.4719101123277364 |1        |0          |0               |0          |0   |0   |0   |0   |0   |0   |0   |0   |0   |0    |0    |0    |0    |0    |0    |0    |0    |0    |0    |0    |1        |10   |40          |0                    |25-50th    |Multiple          |unknown   |NM                   |Low_spent_Small_value_payments  |\n",
      "+-----------+-------------+-----------+-----------+---------------------+-------------------+-------------------+---------+-----------+----------------+-----------+----+----+----+----+----+----+----+----+----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+---------+-----+------------+---------------------+-----------+------------------+----------+---------------------+--------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1) Read with full path\n",
    "gold = spark.read.parquet(\"../datamart/gold/feature_store\")\n",
    "\n",
    "# 2) Register & query\n",
    "gold.createOrReplaceTempView(\"gold_view\")\n",
    "spark.sql(\"SELECT COUNT(*) AS total_rows FROM gold_view\").show()\n",
    "spark.sql(\"SELECT * FROM gold_view LIMIT 200\").show(truncate=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "945e73e8-057d-4318-9c1f-1eb83e6233f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: /app/notebooks\n",
      "Here: ['eda.ipynb', '.ipynb_checkpoints']\n",
      "Up one: ['docker-compose.yaml', 'datamart', '.DS_Store', 'requirements.txt', 'Dockerfile', 'utils', '.gitignore', '.ipynb_checkpoints', '.git', 'main.py', 'data', 'notebooks']\n",
      "Gold dir listing: ['.gitkeep', 'feature_store']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"CWD:\", os.getcwd())\n",
    "print(\"Here:\", os.listdir(\".\"))\n",
    "print(\"Up one:\", os.listdir(\"..\"))\n",
    "print(\"Gold dir listing:\", os.listdir(os.path.join(\"..\", \"datamart\", \"gold\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b303105a-a305-4f85-b452-d7599cb593f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/19 16:37:10 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# 1) Get (or create) the Spark session\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# 2) Read the Gold feature store (relative to /app/notebooks)\n",
    "gold = spark.read.parquet(\"../datamart/gold/feature_store\")\n",
    "\n",
    "# 3) Coalesce into 1 file and write CSV with header\n",
    "gold.coalesce(1) \\\n",
    "    .write \\\n",
    "    .option(\"header\", True) \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .csv(\"../export/gold_csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efa50a3e-11d3-4fe3-a354-06e90da20904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export folders: ['gold_csv']\n",
      "CSV parts: ['._SUCCESS.crc', '.part-00000-6d9bc5c7-59f0-462c-9918-36c636a5ac11-c000.csv.crc', '_SUCCESS', 'part-00000-6d9bc5c7-59f0-462c-9918-36c636a5ac11-c000.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"Export folders:\", os.listdir(\"../export\"))\n",
    "print(\"CSV parts:\", os.listdir(\"../export/gold_csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58919afd-2066-470e-8c4b-f212165b229c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
